# ë‰´ìŠ¤ í¬ë¡¤ë§ ì„œë²„

ë¹„ë™ê¸° ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œìŠ¤í…œìœ¼ë¡œ RSS í”¼ë“œ ìˆ˜ì§‘ê³¼ ì›¹ í¬ë¡¤ë§ì„ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **ë¹„ë™ê¸° RSS í”¼ë“œ ìˆ˜ì§‘** (aiohttp)
- **ì›¹ í¬ë¡¤ë§** (BeautifulSoup4, robots.txt ì¤€ìˆ˜)
- **ìŠ¤ì¼€ì¤„ë§** (APScheduler)
- **ìë™ ì¬ì‹œë„** (tenacity)
- **PostgreSQL ì €ì¥** (SQLAlchemy)
- **ì‹œì‚¬ì˜¤ëŠ˜ ì „ìš© í¬ë¡¤ëŸ¬**
- **ëª¨ë“ˆí™”ëœ êµ¬ì¡°**

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
crawling_server/
â”‚
â”œâ”€â”€ web_crawler/
â”‚   â”œâ”€â”€ sisaon_scraper.py         # ì‹œì‚¬ì˜¤ëŠ˜ ê¸°ìë³„ ê¸°ì‚¬ í¬ë¡¤ë§
â”‚   â”œâ”€â”€ general_scraper.py        # íƒ€ ì‹ ë¬¸ì‚¬ ì›¹ í¬ë¡¤ë§
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ parser_utils.py       # HTML íŒŒì‹± ê³µí†µ í•¨ìˆ˜
â”‚       â””â”€â”€ request_utils.py      # ìš”ì²­/í—¤ë” ê´€ë¦¬ í•¨ìˆ˜
â”‚
â”œâ”€â”€ rss_collector/
â”‚   â”œâ”€â”€ feed_fetcher.py           # aiohttpë¡œ RSS URLë“¤ ë¹„ë™ê¸° ìš”ì²­
â”‚   â”œâ”€â”€ feed_parser.py            # feedparserë¡œ RSS íŒŒì‹±
â”‚   â””â”€â”€ rss_sources.yaml          # ìˆ˜ì§‘í•  RSS ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸ ì„¤ì •
â”‚
â”œâ”€â”€ scheduler/
â”‚   â””â”€â”€ job_manager.py            # APSchedulerë¡œ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ ê´€ë¦¬
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # DB ì—°ê²°ì •ë³´, í™˜ê²½ì„¤ì •, ë¡œê¹…
â”‚
â””â”€â”€ main.py                       # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì§„ì…ì 
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# ë˜ëŠ”
venv\Scripts\activate     # Windows
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
export DB_HOST=localhost
export DB_PORT=5432
export DB_NAME=newspaper_db
export DB_USER=postgres
export DB_PASSWORD=your_password
```

### 4. PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±

```sql
CREATE DATABASE newspaper_db;
```

## ğŸš€ ì‚¬ìš©ë²•

### ì „ì²´ ì„œë²„ ì‹¤í–‰

```bash
cd crawling_server
python main.py
```

### RSS ìˆ˜ì§‘ë§Œ ì‹¤í–‰

```bash
python main.py rss                    # ëª¨ë“  ì†ŒìŠ¤
python main.py rss sisaoneul          # íŠ¹ì • ì†ŒìŠ¤ë§Œ
```

### ì›¹ í¬ë¡¤ë§ë§Œ ì‹¤í–‰

```bash
python main.py crawl                  # ëª¨ë“  ì†ŒìŠ¤
python main.py crawl sisaoneul        # íŠ¹ì • ì†ŒìŠ¤ë§Œ
```

### ì„œë²„ ìƒíƒœ í™•ì¸

```bash
python main.py status
```

## âš™ï¸ ì„¤ì •

### RSS ì†ŒìŠ¤ ì„¤ì •

`crawling_server/rss_collector/rss_sources.yaml` íŒŒì¼ì—ì„œ RSS í”¼ë“œ URLê³¼ í¬ë¡¤ë§ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

```yaml
rss_sources:
  sisaoneul:
    name: "ì‹œì‚¬ì˜¤ëŠ˜"
    base_url: "https://www.sisaoneul.com"
    feeds:
      - url: "https://www.sisaoneul.com/rss.xml"
        category: "ì „ì²´"

crawling_settings:
  enabled_sources:
    - sisaoneul
    - yonhap
    - hankookilbo
  
  priorities:
    sisaoneul: 10
    yonhap: 8
  
  intervals:
    sisaoneul: 30    # 30ë¶„ë§ˆë‹¤
    yonhap: 60       # 60ë¶„ë§ˆë‹¤
```

### í¬ë¡¤ë§ ì„¤ì •

`crawling_server/config/settings.py`ì—ì„œ í¬ë¡¤ë§ ê´€ë ¨ ì„¤ì •ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
CRAWLING_CONFIG = {
    'request_delay': 1.0,  # ìš”ì²­ ê°„ê²© (ì´ˆ)
    'timeout': 30,         # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    'max_retries': 3,      # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
}
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸

```bash
tail -f logs/crawler.log
```

### ì‘ì—… ìƒíƒœ ì¡°íšŒ

```python
from crawling_server.scheduler.job_manager import JobManager

job_manager = JobManager()
status = job_manager.get_scheduler_info()
print(status)
```

## ğŸ”§ ê°œë°œ

### ìƒˆë¡œìš´ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ì¶”ê°€

1. `rss_sources.yaml`ì— RSS í”¼ë“œ URL ì¶”ê°€
2. `general_scraper.py`ì˜ `site_configs`ì— ì‚¬ì´íŠ¸ë³„ ì„ íƒì ì¶”ê°€
3. í•„ìš”ì‹œ ì „ìš© ìŠ¤í¬ë˜í¼ ìƒì„±

### ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë¡œì§ ì¶”ê°€

`main.py`ì˜ ì½œë°± í•¨ìˆ˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤:

```python
async def _on_rss_collection_complete(self, result):
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë¡œì§
    await self._save_articles_to_db(result['articles'])
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **PostgreSQL ì—°ê²° ì‹¤íŒ¨**
   - í™˜ê²½ë³€ìˆ˜ í™•ì¸
   - PostgreSQL ì„œë¹„ìŠ¤ ì‹¤í–‰ ìƒíƒœ í™•ì¸

2. **RSS í”¼ë“œ ì ‘ê·¼ ì‹¤íŒ¨**
   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
   - RSS URL ìœ íš¨ì„± í™•ì¸

3. **í¬ë¡¤ë§ ì‹¤íŒ¨**
   - robots.txt í™•ì¸
   - ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ í™•ì¸

### ë””ë²„ê¹…

```bash
# ìƒì„¸ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
export LOG_LEVEL=DEBUG
python main.py
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ¤ ê¸°ì—¬

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request 